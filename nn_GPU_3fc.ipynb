{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the GPU!\n"
     ]
    }
   ],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU!\")\n",
    "else:\n",
    "    print(\"WARNING: Could not find GPU! Using CPU only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample size of training set is:  3556\n",
      "The sample size of testing set is:  889\n"
     ]
    }
   ],
   "source": [
    "x_train_nhts = np.load(\"data/x_train_nhts.npy\")\n",
    "x_test_nhts = np.load(\"data/x_test_nhts.npy\")\n",
    " \n",
    "x_train_images = np.load(\"data/x_train_images.npy\")\n",
    "x_test_images = np.load(\"data/x_test_images.npy\")\n",
    "  \n",
    "\n",
    "y_train = np.load(\"data/y_train.npy\")\n",
    "y_test = np.load(\"data/y_test.npy\")\n",
    "print(\"The sample size of training set is: \", x_train_nhts.shape[0])\n",
    "print(\"The sample size of testing set is: \", x_test_nhts.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.339426\n",
       "1    0.324241\n",
       "3    0.250562\n",
       "0    0.085771\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bridge numpy to torch\n",
    "x_train_nhts_torch = torch.as_tensor(x_train_nhts).float() # specify floats for the inputs\n",
    "x_train_images_torch = torch.as_tensor(x_train_images).float()\n",
    "x_test_nhts_torch = torch.as_tensor(x_test_nhts).float()\n",
    "x_test_images_torch = torch.as_tensor(x_test_images).float()\n",
    "y_train_torch = torch.as_tensor(y_train[:,0])\n",
    "y_test_torch = torch.as_tensor(y_test[:,0])\n",
    "n_train = x_train_nhts.shape[0]\n",
    "n_test = x_test_nhts.shape[0]\n",
    "# inputs: x_train_nhts, x_train_images, x_test_nhts, x_test_images, y_train, and y_test; \n",
    "K = len(np.unique(y_train))\n",
    "x_dim = x_train_nhts.shape[1]\n",
    "# \n",
    "pd.value_counts(y_train[:,0])/y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Type 1: with only NHTS dataset.\n",
    "class NN(nn.Module):  # subclass nn.Module\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(x_dim, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, K)\n",
    "        self.softmax = nn.Softmax(dim=1)  \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = x.relu()\n",
    "        x = self.fc2(x)\n",
    "        x = x.relu()\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.NN'>\n"
     ]
    }
   ],
   "source": [
    "net = NN().float().to(device)\n",
    "print(type(net))\n",
    "optim = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# \n",
    "n_epoches = 500 # so many?\n",
    "batch_size = 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 1.3827788829803467; test loss: 1.38237464427948\n",
      "Epoch 0: train accuracy: 0.32424071991001124; test accuracy: 0.3160854893138358\n",
      "Epoch 5: train loss: 1.3760267496109009; test loss: 1.3755552768707275\n",
      "Epoch 5: train accuracy: 0.32424071991001124; test accuracy: 0.3160854893138358\n",
      "Epoch 10: train loss: 1.3738867044448853; test loss: 1.3670028448104858\n",
      "Epoch 10: train accuracy: 0.31833520809898763; test accuracy: 0.296962879640045\n",
      "Epoch 15: train loss: 1.3540804386138916; test loss: 1.3576515913009644\n",
      "Epoch 15: train accuracy: 0.33942632170978626; test accuracy: 0.34195725534308213\n",
      "Epoch 20: train loss: 1.3575122356414795; test loss: 1.3496174812316895\n",
      "Epoch 20: train accuracy: 0.33942632170978626; test accuracy: 0.34195725534308213\n",
      "Epoch 25: train loss: 1.326930046081543; test loss: 1.343945026397705\n",
      "Epoch 25: train accuracy: 0.33942632170978626; test accuracy: 0.34195725534308213\n",
      "Epoch 30: train loss: 1.3452272415161133; test loss: 1.3401212692260742\n",
      "Epoch 30: train accuracy: 0.33942632170978626; test accuracy: 0.34195725534308213\n",
      "Epoch 35: train loss: 1.3238595724105835; test loss: 1.3373668193817139\n",
      "Epoch 35: train accuracy: 0.33942632170978626; test accuracy: 0.34195725534308213\n",
      "Epoch 40: train loss: 1.3123399019241333; test loss: 1.3351510763168335\n",
      "Epoch 40: train accuracy: 0.33942632170978626; test accuracy: 0.34195725534308213\n",
      "Epoch 45: train loss: 1.3429677486419678; test loss: 1.3329135179519653\n",
      "Epoch 45: train accuracy: 0.33942632170978626; test accuracy: 0.34195725534308213\n",
      "Epoch 50: train loss: 1.3345301151275635; test loss: 1.3302454948425293\n",
      "Epoch 50: train accuracy: 0.33942632170978626; test accuracy: 0.34195725534308213\n",
      "Epoch 55: train loss: 1.3185096979141235; test loss: 1.3270207643508911\n",
      "Epoch 55: train accuracy: 0.33942632170978626; test accuracy: 0.34195725534308213\n",
      "Epoch 60: train loss: 1.3146594762802124; test loss: 1.3228822946548462\n",
      "Epoch 60: train accuracy: 0.422103487064117; test accuracy: 0.41057367829021374\n",
      "Epoch 65: train loss: 1.3348660469055176; test loss: 1.3177789449691772\n",
      "Epoch 65: train accuracy: 0.38779527559055116; test accuracy: 0.38245219347581555\n",
      "Epoch 70: train loss: 1.307506799697876; test loss: 1.3120079040527344\n",
      "Epoch 70: train accuracy: 0.4108548931383577; test accuracy: 0.40719910011248595\n",
      "Epoch 75: train loss: 1.3039145469665527; test loss: 1.3063890933990479\n",
      "Epoch 75: train accuracy: 0.40804274465691787; test accuracy: 0.41057367829021374\n",
      "Epoch 80: train loss: 1.2897472381591797; test loss: 1.3016265630722046\n",
      "Epoch 80: train accuracy: 0.4094488188976378; test accuracy: 0.4128233970753656\n",
      "Epoch 85: train loss: 1.2927416563034058; test loss: 1.2977205514907837\n",
      "Epoch 85: train accuracy: 0.4094488188976378; test accuracy: 0.4128233970753656\n",
      "Epoch 90: train loss: 1.3118311166763306; test loss: 1.2946386337280273\n",
      "Epoch 90: train accuracy: 0.4094488188976378; test accuracy: 0.4128233970753656\n",
      "Epoch 95: train loss: 1.271070122718811; test loss: 1.2921016216278076\n",
      "Epoch 95: train accuracy: 0.4094488188976378; test accuracy: 0.4128233970753656\n",
      "Epoch 100: train loss: 1.284239411354065; test loss: 1.2899459600448608\n",
      "Epoch 100: train accuracy: 0.4111361079865017; test accuracy: 0.41394825646794153\n",
      "Epoch 105: train loss: 1.298061728477478; test loss: 1.2881139516830444\n",
      "Epoch 105: train accuracy: 0.40832395950506184; test accuracy: 0.41169853768278963\n",
      "Epoch 110: train loss: 1.3290685415267944; test loss: 1.2864375114440918\n",
      "Epoch 110: train accuracy: 0.41001124859392574; test accuracy: 0.4128233970753656\n",
      "Epoch 115: train loss: 1.2874982357025146; test loss: 1.2848488092422485\n",
      "Epoch 115: train accuracy: 0.4296962879640045; test accuracy: 0.4296962879640045\n",
      "Epoch 120: train loss: 1.2364790439605713; test loss: 1.283460021018982\n",
      "Epoch 120: train accuracy: 0.42997750281214847; test accuracy: 0.42857142857142855\n",
      "Epoch 125: train loss: 1.28020179271698; test loss: 1.2820889949798584\n",
      "Epoch 125: train accuracy: 0.4322272215973003; test accuracy: 0.4330708661417323\n",
      "Epoch 130: train loss: 1.283855676651001; test loss: 1.2807848453521729\n",
      "Epoch 130: train accuracy: 0.4322272215973003; test accuracy: 0.4330708661417323\n",
      "Epoch 135: train loss: 1.2613898515701294; test loss: 1.279463768005371\n",
      "Epoch 135: train accuracy: 0.44628796400449944; test accuracy: 0.4454443194600675\n",
      "Epoch 140: train loss: 1.2756558656692505; test loss: 1.2782213687896729\n",
      "Epoch 140: train accuracy: 0.45106861642294716; test accuracy: 0.44769403824521936\n",
      "Epoch 145: train loss: 1.2727793455123901; test loss: 1.2769451141357422\n",
      "Epoch 145: train accuracy: 0.453318335208099; test accuracy: 0.45106861642294716\n",
      "Epoch 150: train loss: 1.2844268083572388; test loss: 1.2757461071014404\n",
      "Epoch 150: train accuracy: 0.4547244094488189; test accuracy: 0.4544431946006749\n",
      "Epoch 155: train loss: 1.2576738595962524; test loss: 1.274590253829956\n",
      "Epoch 155: train accuracy: 0.4547244094488189; test accuracy: 0.4544431946006749\n",
      "Epoch 160: train loss: 1.2577327489852905; test loss: 1.2734757661819458\n",
      "Epoch 160: train accuracy: 0.4547244094488189; test accuracy: 0.4544431946006749\n",
      "Epoch 165: train loss: 1.2700437307357788; test loss: 1.272339105606079\n",
      "Epoch 165: train accuracy: 0.4547244094488189; test accuracy: 0.4544431946006749\n",
      "Epoch 170: train loss: 1.2898024320602417; test loss: 1.2712335586547852\n",
      "Epoch 170: train accuracy: 0.4558492688413948; test accuracy: 0.45556805399325084\n",
      "Epoch 175: train loss: 1.2723026275634766; test loss: 1.2701689004898071\n",
      "Epoch 175: train accuracy: 0.45725534308211474; test accuracy: 0.45556805399325084\n",
      "Epoch 180: train loss: 1.279427170753479; test loss: 1.2691525220870972\n",
      "Epoch 180: train accuracy: 0.4575365579302587; test accuracy: 0.4566929133858268\n",
      "Epoch 185: train loss: 1.2731497287750244; test loss: 1.2681957483291626\n",
      "Epoch 185: train accuracy: 0.4609111361079865; test accuracy: 0.46569178852643417\n",
      "Epoch 190: train loss: 1.2407021522521973; test loss: 1.2671416997909546\n",
      "Epoch 190: train accuracy: 0.4609111361079865; test accuracy: 0.4611923509561305\n",
      "Epoch 195: train loss: 1.261517882347107; test loss: 1.2661645412445068\n",
      "Epoch 195: train accuracy: 0.46484814398200225; test accuracy: 0.46006749156355453\n",
      "Epoch 200: train loss: 1.2655025720596313; test loss: 1.2652688026428223\n",
      "Epoch 200: train accuracy: 0.4637232845894263; test accuracy: 0.45894263217097864\n",
      "Epoch 205: train loss: 1.2683948278427124; test loss: 1.2644261121749878\n",
      "Epoch 205: train accuracy: 0.46934758155230594; test accuracy: 0.4701912260967379\n",
      "Epoch 210: train loss: 1.2408230304718018; test loss: 1.2636629343032837\n",
      "Epoch 210: train accuracy: 0.46991001124859394; test accuracy: 0.46794150731158607\n",
      "Epoch 215: train loss: 1.2641081809997559; test loss: 1.2629382610321045\n",
      "Epoch 215: train accuracy: 0.4704724409448819; test accuracy: 0.46906636670416196\n",
      "Epoch 220: train loss: 1.2777284383773804; test loss: 1.262154221534729\n",
      "Epoch 220: train accuracy: 0.46062992125984253; test accuracy: 0.45894263217097864\n",
      "Epoch 225: train loss: 1.26901376247406; test loss: 1.2615553140640259\n",
      "Epoch 225: train accuracy: 0.46962879640044997; test accuracy: 0.4645669291338583\n",
      "Epoch 230: train loss: 1.2607682943344116; test loss: 1.260931372642517\n",
      "Epoch 230: train accuracy: 0.4730033745781777; test accuracy: 0.47131608548931386\n",
      "Epoch 235: train loss: 1.2679975032806396; test loss: 1.2602183818817139\n",
      "Epoch 235: train accuracy: 0.4620359955005624; test accuracy: 0.4578177727784027\n",
      "Epoch 240: train loss: 1.2690176963806152; test loss: 1.2596627473831177\n",
      "Epoch 240: train accuracy: 0.46737907761529807; test accuracy: 0.45556805399325084\n",
      "Epoch 245: train loss: 1.2984956502914429; test loss: 1.2590831518173218\n",
      "Epoch 245: train accuracy: 0.46962879640044997; test accuracy: 0.46006749156355453\n",
      "Epoch 250: train loss: 1.234711766242981; test loss: 1.258486032485962\n",
      "Epoch 250: train accuracy: 0.4735658042744657; test accuracy: 0.4645669291338583\n",
      "Epoch 255: train loss: 1.2598508596420288; test loss: 1.2579962015151978\n",
      "Epoch 255: train accuracy: 0.46484814398200225; test accuracy: 0.4645669291338583\n",
      "Epoch 260: train loss: 1.2837203741073608; test loss: 1.2574434280395508\n",
      "Epoch 260: train accuracy: 0.4676602924634421; test accuracy: 0.45894263217097864\n",
      "Epoch 265: train loss: 1.2549731731414795; test loss: 1.2568302154541016\n",
      "Epoch 265: train accuracy: 0.48678290213723285; test accuracy: 0.47919010123734535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270: train loss: 1.2371588945388794; test loss: 1.256300687789917\n",
      "Epoch 270: train accuracy: 0.48790776152980875; test accuracy: 0.4780652418447694\n",
      "Epoch 275: train loss: 1.211729645729065; test loss: 1.2558505535125732\n",
      "Epoch 275: train accuracy: 0.47412823397075365; test accuracy: 0.47244094488188976\n",
      "Epoch 280: train loss: 1.2623273134231567; test loss: 1.2552651166915894\n",
      "Epoch 280: train accuracy: 0.47862767154105734; test accuracy: 0.4735658042744657\n",
      "Epoch 285: train loss: 1.2444339990615845; test loss: 1.2549265623092651\n",
      "Epoch 285: train accuracy: 0.4746906636670416; test accuracy: 0.47244094488188976\n",
      "Epoch 290: train loss: 1.235558271408081; test loss: 1.254415512084961\n",
      "Epoch 290: train accuracy: 0.47750281214848145; test accuracy: 0.4735658042744657\n",
      "Epoch 295: train loss: 1.232056736946106; test loss: 1.2540253400802612\n",
      "Epoch 295: train accuracy: 0.4721597300337458; test accuracy: 0.47131608548931386\n",
      "Epoch 300: train loss: 1.2614485025405884; test loss: 1.2535786628723145\n",
      "Epoch 300: train accuracy: 0.4772215973003375; test accuracy: 0.4746906636670416\n",
      "Epoch 305: train loss: 1.261498212814331; test loss: 1.2532844543457031\n",
      "Epoch 305: train accuracy: 0.47272215973003373; test accuracy: 0.46794150731158607\n",
      "Epoch 310: train loss: 1.2928695678710938; test loss: 1.2528049945831299\n",
      "Epoch 310: train accuracy: 0.4746906636670416; test accuracy: 0.4701912260967379\n",
      "Epoch 315: train loss: 1.2781727313995361; test loss: 1.252425193786621\n",
      "Epoch 315: train accuracy: 0.4746906636670416; test accuracy: 0.46794150731158607\n",
      "Epoch 320: train loss: 1.2375627756118774; test loss: 1.2521111965179443\n",
      "Epoch 320: train accuracy: 0.46794150731158607; test accuracy: 0.4645669291338583\n",
      "Epoch 325: train loss: 1.2305554151535034; test loss: 1.251699686050415\n",
      "Epoch 325: train accuracy: 0.47075365579302586; test accuracy: 0.4634420697412823\n",
      "Epoch 330: train loss: 1.2535076141357422; test loss: 1.251228928565979\n",
      "Epoch 330: train accuracy: 0.484814398200225; test accuracy: 0.48256467941507314\n",
      "Epoch 335: train loss: 1.2910963296890259; test loss: 1.2509633302688599\n",
      "Epoch 335: train accuracy: 0.4701912260967379; test accuracy: 0.4634420697412823\n",
      "Epoch 340: train loss: 1.228943109512329; test loss: 1.2506263256072998\n",
      "Epoch 340: train accuracy: 0.4730033745781777; test accuracy: 0.46569178852643417\n",
      "Epoch 345: train loss: 1.2843334674835205; test loss: 1.2502485513687134\n",
      "Epoch 345: train accuracy: 0.4769403824521935; test accuracy: 0.47244094488188976\n",
      "Epoch 350: train loss: 1.2254325151443481; test loss: 1.2499464750289917\n",
      "Epoch 350: train accuracy: 0.47665916760404947; test accuracy: 0.46906636670416196\n",
      "Epoch 355: train loss: 1.260190725326538; test loss: 1.2496237754821777\n",
      "Epoch 355: train accuracy: 0.48031496062992124; test accuracy: 0.4780652418447694\n",
      "Epoch 360: train loss: 1.2882535457611084; test loss: 1.2493759393692017\n",
      "Epoch 360: train accuracy: 0.4676602924634421; test accuracy: 0.4645669291338583\n",
      "Epoch 365: train loss: 1.247198462486267; test loss: 1.2491819858551025\n",
      "Epoch 365: train accuracy: 0.47412823397075365; test accuracy: 0.46906636670416196\n",
      "Epoch 370: train loss: 1.2682418823242188; test loss: 1.248926043510437\n",
      "Epoch 370: train accuracy: 0.4746906636670416; test accuracy: 0.4701912260967379\n",
      "Epoch 375: train loss: 1.2452704906463623; test loss: 1.2486313581466675\n",
      "Epoch 375: train accuracy: 0.47750281214848145; test accuracy: 0.4701912260967379\n",
      "Epoch 380: train loss: 1.2457759380340576; test loss: 1.2482855319976807\n",
      "Epoch 380: train accuracy: 0.47834645669291337; test accuracy: 0.4701912260967379\n",
      "Epoch 385: train loss: 1.2353236675262451; test loss: 1.2480499744415283\n",
      "Epoch 385: train accuracy: 0.4794713160854893; test accuracy: 0.46906636670416196\n",
      "Epoch 390: train loss: 1.2482826709747314; test loss: 1.247732400894165\n",
      "Epoch 390: train accuracy: 0.48256467941507314; test accuracy: 0.4701912260967379\n",
      "Epoch 395: train loss: 1.223955750465393; test loss: 1.2473948001861572\n",
      "Epoch 395: train accuracy: 0.4794713160854893; test accuracy: 0.46794150731158607\n",
      "Epoch 400: train loss: 1.2082797288894653; test loss: 1.2470839023590088\n",
      "Epoch 400: train accuracy: 0.4932508436445444; test accuracy: 0.4746906636670416\n",
      "Epoch 405: train loss: 1.2284072637557983; test loss: 1.2469648122787476\n",
      "Epoch 405: train accuracy: 0.48087739032620924; test accuracy: 0.4645669291338583\n",
      "Epoch 410: train loss: 1.2678011655807495; test loss: 1.246739387512207\n",
      "Epoch 410: train accuracy: 0.4828458942632171; test accuracy: 0.4645669291338583\n",
      "Epoch 415: train loss: 1.1994128227233887; test loss: 1.2463380098342896\n",
      "Epoch 415: train accuracy: 0.48509561304836896; test accuracy: 0.46569178852643417\n",
      "Epoch 420: train loss: 1.2517590522766113; test loss: 1.2461185455322266\n",
      "Epoch 420: train accuracy: 0.48340832395950506; test accuracy: 0.4645669291338583\n",
      "Epoch 425: train loss: 1.2549725770950317; test loss: 1.2458596229553223\n",
      "Epoch 425: train accuracy: 0.484533183352081; test accuracy: 0.4645669291338583\n",
      "Epoch 430: train loss: 1.2458668947219849; test loss: 1.2456305027008057\n",
      "Epoch 430: train accuracy: 0.484533183352081; test accuracy: 0.4645669291338583\n",
      "Epoch 435: train loss: 1.2324186563491821; test loss: 1.2453051805496216\n",
      "Epoch 435: train accuracy: 0.4859392575928009; test accuracy: 0.46569178852643417\n",
      "Epoch 440: train loss: 1.2696703672409058; test loss: 1.2453058958053589\n",
      "Epoch 440: train accuracy: 0.48200224971878514; test accuracy: 0.4611923509561305\n",
      "Epoch 445: train loss: 1.1985305547714233; test loss: 1.244876503944397\n",
      "Epoch 445: train accuracy: 0.484251968503937; test accuracy: 0.46231721034870643\n",
      "Epoch 450: train loss: 1.2090500593185425; test loss: 1.244645118713379\n",
      "Epoch 450: train accuracy: 0.484251968503937; test accuracy: 0.46231721034870643\n",
      "Epoch 455: train loss: 1.2510923147201538; test loss: 1.2444007396697998\n",
      "Epoch 455: train accuracy: 0.484814398200225; test accuracy: 0.46231721034870643\n",
      "Epoch 460: train loss: 1.2346090078353882; test loss: 1.2441755533218384\n",
      "Epoch 460: train accuracy: 0.484251968503937; test accuracy: 0.46231721034870643\n",
      "Epoch 465: train loss: 1.235736608505249; test loss: 1.243889570236206\n",
      "Epoch 465: train accuracy: 0.484814398200225; test accuracy: 0.46231721034870643\n",
      "Epoch 470: train loss: 1.2282695770263672; test loss: 1.2436587810516357\n",
      "Epoch 470: train accuracy: 0.48368953880764903; test accuracy: 0.4634420697412823\n",
      "Epoch 475: train loss: 1.2655810117721558; test loss: 1.2434501647949219\n",
      "Epoch 475: train accuracy: 0.48368953880764903; test accuracy: 0.46231721034870643\n",
      "Epoch 480: train loss: 1.1905553340911865; test loss: 1.2431914806365967\n",
      "Epoch 480: train accuracy: 0.49015748031496065; test accuracy: 0.47244094488188976\n",
      "Epoch 485: train loss: 1.2345185279846191; test loss: 1.2429803609848022\n",
      "Epoch 485: train accuracy: 0.4955005624296963; test accuracy: 0.4769403824521935\n",
      "Epoch 490: train loss: 1.2365186214447021; test loss: 1.2428350448608398\n",
      "Epoch 490: train accuracy: 0.49128233970753654; test accuracy: 0.47131608548931386\n",
      "Epoch 495: train loss: 1.2357245683670044; test loss: 1.2425373792648315\n",
      "Epoch 495: train accuracy: 0.49437570303712036; test accuracy: 0.4769403824521935\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "for n_epoch in range(n_epoches):\n",
    "    # create permutation for batch training\n",
    "    permutation = torch.randperm(x_train_nhts_torch.size()[0])\n",
    "    for i in range(0, x_train_nhts_torch.size()[0], batch_size):\n",
    "        # clear gradients first (for each iteration!)!\n",
    "        optim.zero_grad()\n",
    "        # forward pass\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = x_train_nhts_torch[indices].to(device), y_train_torch[indices].to(device)\n",
    "        batch_y_pred_train = net(batch_x).to(device)\n",
    "        # loss \n",
    "        loss = criterion(batch_y_pred_train.squeeze(), batch_y)\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        # one step optim\n",
    "        optim.step()\n",
    "\n",
    "    # eval training accuracy\n",
    "    y_pred_train = net(x_train_nhts_torch.to(device))\n",
    "    loss_train = criterion(y_pred_train.squeeze(), y_train_torch.to(device))\n",
    "    train_losses.append(loss_train)\n",
    "    _, predict_train = torch.max(y_pred_train, axis = 1)\n",
    "    accuracy_train = (predict_train == y_train_torch.to(device)).sum().item()/n_train  \n",
    "    train_accuracies.append(accuracy_train)\n",
    "    # evaluate testing sets step-wise\n",
    "    net.eval()\n",
    "    y_pred_test = net(x_test_nhts_torch.to(device))\n",
    "    loss_test = criterion(y_pred_test.squeeze(), y_test_torch.to(device))\n",
    "    test_losses.append(loss_test)\n",
    "    _, predict_test = torch.max(y_pred_test.to(device), axis = 1)\n",
    "    accuracy_test = (predict_test == y_test_torch.to(device)).sum().item()/n_test\n",
    "    test_accuracies.append(accuracy_test)\n",
    "    # print info    \n",
    "    if n_epoch % 5 == 0:\n",
    "        print('Epoch {}: train loss: {}; test loss: {}'.format(n_epoch, loss.item(), loss_test.item()))\n",
    "        print('Epoch {}: train accuracy: {}; test accuracy: {}'.format(n_epoch, accuracy_train, accuracy_test)) \n",
    "# Note: about 60% accuracy for both training and testing. (with n_epoches = 500; batch_size = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label = \"train loss\")\n",
    "plt.plot(test_losses, label = \"test loss\")\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accuracies, label = \"train accuracy\")\n",
    "plt.plot(test_accuracies, label = \"test accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"data/nn_ADAM_3fc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
